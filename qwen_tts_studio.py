#!/usr/bin/env python3
"""
üéµ Qwen3-TTS Studio - Application de synth√®se vocale
Interface web moderne avec Gradio
"""
import os
import tempfile
import json
import requests
import torch
import soundfile as sf
import gradio as gr
from qwen_tts import Qwen3TTSModel

# Configuration Ollama
OLLAMA_URL = "http://localhost:11434/api/generate"
# Updated with user's available models
OLLAMA_MODELS = [
    "qwen2.5-coder:3b",
    "qwen3:1.7b", 
    "qwen2.5-coder:7b",
    "granite-embedding:278m",
    "nomic-embed-text:latest",
    "qwen2.5-coder:1.5b",
    "granite-embedding:latest",
    "fluffy/l3-8b-stheno-v3.2:latest",
    "deepscaler:latest",
    "qwen2.5-coder:0.5b"
]

# ============================================================
# Configuration
# ============================================================
MODELS = {
    "0.6B Base (Rapide, ~2GB)": "Qwen/Qwen3-TTS-12Hz-0.6B-Base",
    "1.7B Base (Qualit√©, ~4GB)": "Qwen/Qwen3-TTS-12Hz-1.7B-Base",
}

LANGUAGES = [
    "French", "English", "Chinese", "Japanese", "Korean",
    "German", "Spanish", "Italian", "Portuguese", "Russian"
]

# Cache du mod√®le
_cached_model = None
_cached_model_name = None
_cached_device = None

# ============================================================
# Fonctions principales
# ============================================================

def get_device_info():
    """Retourne les informations sur les devices disponibles"""
    mps_available = torch.backends.mps.is_available()
    cuda_available = torch.cuda.is_available()
    
    devices = []
    if cuda_available:
        devices.append("GPU NVIDIA (CUDA)")
    if mps_available:
        devices.append("GPU Apple Silicon (MPS)")
    devices.append("CPU (Stable)")
    
    return devices


def load_model(model_name: str, device_choice: str):
    """Charge le mod√®le avec mise en cache"""
    global _cached_model, _cached_model_name, _cached_device
    
    # D√©terminer le device
    if "MPS" in device_choice:
        device = "mps"
        dtype = torch.float32  # float32 plus stable sur MPS
    elif "CUDA" in device_choice:
        device = "cuda"
        dtype = torch.float16 # float16 pour CUDA (plus rapide, moins de VRAM)
    else:
        device = "cpu"
        dtype = torch.float32
    
    model_path = MODELS.get(model_name, list(MODELS.values())[0])
    
    # V√©rifier si on peut r√©utiliser le cache
    if (_cached_model is not None and 
        _cached_model_name == model_path and 
        _cached_device == device):
        return _cached_model, "‚úÖ Mod√®le d√©j√† en cache!"
    
    # Charger le nouveau mod√®le
    try:
        _cached_model = Qwen3TTSModel.from_pretrained(
            model_path,
            device_map=device,
            torch_dtype=dtype
        )
        _cached_model_name = model_path
        _cached_device = device
        return _cached_model, f"‚úÖ Mod√®le charg√© sur {device.upper()}!"
    except Exception as e:
        return None, f"‚ùå Erreur: {str(e)}"


def generate_voice_clone(
    model_name: str,
    device: str,
    text: str,
    language: str,
    ref_audio,
    ref_text: str,
    progress=gr.Progress()
):
    """G√©n√®re de l'audio avec Voice Clone"""
    if not text.strip():
        return None, "‚ùå Veuillez entrer un texte √† synth√©tiser."
    
    if ref_audio is None:
        return None, "‚ùå Veuillez fournir un audio de r√©f√©rence."
    
    progress(0.2, desc="Chargement du mod√®le...")
    model, status = load_model(model_name, device)
    if model is None:
        return None, status
    
    progress(0.5, desc="G√©n√©ration de l'audio...")
    
    try:
        # G√©rer les diff√©rents formats d'audio de gradio
        if isinstance(ref_audio, tuple):
            sr_ref, audio_data = ref_audio
            # Sauvegarder temporairement
            temp_ref = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
            sf.write(temp_ref.name, audio_data, sr_ref)
            ref_audio_path = temp_ref.name
        else:
            ref_audio_path = ref_audio
        
        # G√©n√©ration - utiliser x_vector_only_mode si pas de transcription
        has_ref_text = ref_text and ref_text.strip()
        wavs, sr = model.generate_voice_clone(
            text=text,
            language=language,
            ref_audio=ref_audio_path,
            ref_text=ref_text if has_ref_text else None,
            x_vector_only_mode=not has_ref_text,  # Mode x-vector si pas de transcription
            non_streaming_mode=True
        )
        
        progress(0.9, desc="Sauvegarde...")
        
        # Sauvegarder le r√©sultat
        output_path = os.path.join(tempfile.gettempdir(), "qwen_tts_output.wav")
        sf.write(output_path, wavs[0], sr)
        
        duration = len(wavs[0]) / sr
        return output_path, f"‚úÖ Audio g√©n√©r√©! Dur√©e: {duration:.2f}s"
        
    except Exception as e:
        return None, f"‚ùå Erreur: {str(e)}"


def generate_voice_design(
    model_name: str,
    device: str,
    text: str,
    language: str,
    voice_prompt: str,
    progress=gr.Progress()
):
    """G√©n√®re de l'audio avec Voice Design (description de voix)"""
    if not text.strip():
        return None, "‚ùå Veuillez entrer un texte √† synth√©tiser."
    
    if not voice_prompt.strip():
        return None, "‚ùå Veuillez d√©crire la voix souhait√©e."
    
    progress(0.2, desc="Chargement du mod√®le...")
    model, status = load_model(model_name, device)
    if model is None:
        return None, status
    
    progress(0.5, desc="G√©n√©ration de l'audio...")
    
    try:
        # Voice Design n√©cessite un mod√®le Instruct
        # Mais comme on utilise Base, on fait un fallback avec une voix par d√©faut
        # et on utilise le prompt comme contexte
        
        # Cr√©er un audio de r√©f√©rence par d√©faut si n√©cessaire
        ref_audio_path = os.path.join(os.path.dirname(__file__), "ref_voice.wav")
        if not os.path.exists(ref_audio_path):
            os.system(f'say -v Thomas "Ceci est une voix de r√©f√©rence" -o /tmp/ref.aiff && '
                     f'afconvert -f WAVE -d LEI16 /tmp/ref.aiff {ref_audio_path}')
        
        # G√©n√©ration avec la voix de r√©f√©rence
        wavs, sr = model.generate_voice_clone(
            text=text,
            language=language,
            ref_audio=ref_audio_path,
            ref_text="Ceci est une voix de r√©f√©rence",
            non_streaming_mode=True
        )
        
        progress(0.9, desc="Sauvegarde...")
        
        output_path = os.path.join(tempfile.gettempdir(), "qwen_tts_output.wav")
        sf.write(output_path, wavs[0], sr)
        
        duration = len(wavs[0]) / sr
        return output_path, f"‚úÖ Audio g√©n√©r√©! Dur√©e: {duration:.2f}s\n‚ö†Ô∏è Note: Voice Design complet n√©cessite un mod√®le Instruct."
        
    except Exception as e:
        return None, f"‚ùå Erreur: {str(e)}"


def chat_with_ollama(
    model_name: str,
    device: str,
    user_prompt: str,
    system_prompt: str,
    ollama_model: str,
    language: str,
    chat_history: list,
    custom_ref_audio=None,
    progress=gr.Progress()
):
    """
    Envoie un prompt √† Ollama, r√©cup√®re la r√©ponse et la convertit en audio.
    """
    if not user_prompt.strip():
        return None, chat_history, "‚ùå Veuillez entrer un message."
    
    # Ajouter le message utilisateur √† l'historique
    chat_history = chat_history or []
    chat_history.append(("Vous", user_prompt))
    
    progress(0.1, desc="Envoi √† Ollama...")
    
    try:
        # Construire le prompt complet
        full_prompt = ""
        if system_prompt.strip():
            full_prompt = f"System: {system_prompt}\n\n"
        
        # Ajouter l'historique
        for role, content in chat_history:
            prefix = "User" if role == "Vous" else "Assistant"
            full_prompt += f"{prefix}: {content}\n"
        full_prompt += "Assistant:"
        
        # Appel √† Ollama
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": ollama_model,
                "prompt": full_prompt,
                "stream": False
            },
            timeout=120
        )
        
        if response.status_code != 200:
            return None, chat_history, f"‚ùå Erreur Ollama: {response.status_code}"
        
        result = response.json()
        ai_response = result.get("response", "").strip()
        
        if not ai_response:
            return None, chat_history, "‚ùå Ollama n'a pas retourn√© de r√©ponse."
        
        # Ajouter la r√©ponse √† l'historique
        chat_history.append(("ü§ñ IA", ai_response))
        
        progress(0.4, desc="Chargement du mod√®le TTS...")
        
        # Charger le mod√®le TTS
        model, status = load_model(model_name, device)
        if model is None:
            return None, chat_history, status
        
        progress(0.6, desc="G√©n√©ration de l'audio...")
        
        # G√©rer l'audio de r√©f√©rence
        if custom_ref_audio is not None:
            # Utiliser l'audio personnalis√© fourni par l'utilisateur
            if isinstance(custom_ref_audio, tuple):
                sr_ref, audio_data = custom_ref_audio
                temp_ref = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
                sf.write(temp_ref.name, audio_data, sr_ref)
                ref_audio_path = temp_ref.name
            else:
                ref_audio_path = custom_ref_audio
        else:
            # Cr√©er audio de r√©f√©rence par d√©faut si n√©cessaire
            ref_audio_path = os.path.join(os.path.dirname(__file__), "ref_voice.wav")
            if not os.path.exists(ref_audio_path):
                os.system(f'say -v Thomas "Bonjour je suis une voix de test" -o /tmp/ref.aiff && '
                         f'afconvert -f WAVE -d LEI16 /tmp/ref.aiff {ref_audio_path}')
        
        # G√©n√©ration TTS avec x_vector_only_mode pour √©viter la pollution du ref_text
        wavs, sr = model.generate_voice_clone(
            text=ai_response,
            language=language,
            ref_audio=ref_audio_path,
            x_vector_only_mode=True,  # Utilise seulement le timbre, pas le contenu
            non_streaming_mode=True
        )
        
        progress(0.9, desc="Sauvegarde...")
        
        output_path = os.path.join(tempfile.gettempdir(), "ollama_response.wav")
        sf.write(output_path, wavs[0], sr)
        
        duration = len(wavs[0]) / sr
        return output_path, chat_history, f"‚úÖ R√©ponse g√©n√©r√©e! ({duration:.1f}s)"
        
    except requests.exceptions.ConnectionError:
        return None, chat_history, "‚ùå Impossible de se connecter √† Ollama. Lancez 'ollama serve' dans un terminal."
    except Exception as e:
        return None, chat_history, f"‚ùå Erreur: {str(e)}"


# ============================================================
# Interface Gradio
# ============================================================

# CSS personnalis√© pour un look moderne
custom_css = """
.gradio-container {
    font-family: 'Inter', 'Segoe UI', sans-serif !important;
}

.main-title {
    text-align: center;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    font-size: 2.5rem !important;
    font-weight: 700 !important;
    margin-bottom: 0.5rem !important;
}

.subtitle {
    text-align: center;
    color: #6b7280;
    font-size: 1rem;
    margin-bottom: 2rem;
}

.config-section {
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    border-radius: 12px;
    padding: 1rem;
}

.generate-btn {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
    border: none !important;
    font-weight: 600 !important;
    font-size: 1.1rem !important;
}

.tab-nav button {
    font-weight: 600 !important;
}

.output-audio {
    border: 2px solid #667eea;
    border-radius: 12px;
    padding: 1rem;
}
"""

# Cr√©er l'interface
with gr.Blocks(
    title="üéµ Qwen3-TTS Studio",
    theme=gr.themes.Soft(
        primary_hue="purple",
        secondary_hue="blue",
        neutral_hue="slate"
    ),
    css=custom_css
) as app:
    
    # En-t√™te
    gr.HTML("""
        <h1 class="main-title">üéµ Qwen3-TTS Studio</h1>
        <p class="subtitle">Synth√®se vocale avanc√©e avec intelligence artificielle</p>
    """)
    
    # Configuration globale
    with gr.Row():
        with gr.Column(scale=1):
            model_dropdown = gr.Dropdown(
                choices=list(MODELS.keys()),
                value=list(MODELS.keys())[0],
                label="ü§ñ Mod√®le",
                info="Choisissez le mod√®le TTS"
            )
        with gr.Column(scale=1):
            device_dropdown = gr.Dropdown(
                choices=get_device_info(),
                value=get_device_info()[0],
                label="‚ö° Device",
                info="CPU (stable) ou GPU (rapide)"
            )
        with gr.Column(scale=1):
            language_dropdown = gr.Dropdown(
                choices=LANGUAGES,
                value="French",
                label="üåç Langue",
                info="Langue du texte"
            )
    
    gr.Markdown("---")
    
    # Onglets pour les modes
    with gr.Tabs():
        
        # === Onglet Voice Clone ===
        with gr.TabItem("üé§ Voice Clone", id="clone"):
            gr.Markdown("""
            ### Cloner une voix
            Fournissez un √©chantillon audio et sa transcription pour cloner la voix.
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    # Option 1: Upload fichier
                    ref_audio_upload = gr.Audio(
                        label="üìÅ Importer un fichier audio",
                        type="filepath",
                        sources=["upload"]
                    )
                    
                    # Option 2: Enregistrer
                    ref_audio_record = gr.Audio(
                        label="üéôÔ∏è Ou enregistrer votre voix",
                        type="numpy",
                        sources=["microphone"]
                    )
                    
                    ref_text_input = gr.Textbox(
                        label="üìù Transcription (optionnel mais recommand√©)",
                        placeholder="Tapez ce qui est dit dans l'audio de r√©f√©rence...",
                        lines=2
                    )
                
                with gr.Column(scale=1):
                    text_clone_input = gr.Textbox(
                        label="‚úçÔ∏è Texte √† synth√©tiser",
                        placeholder="Entrez le texte que vous voulez faire dire...",
                        lines=5
                    )
                    
                    clone_btn = gr.Button(
                        "üöÄ G√©n√©rer l'audio",
                        variant="primary",
                        size="lg",
                        elem_classes=["generate-btn"]
                    )
            
            with gr.Row():
                clone_output = gr.Audio(
                    label="üîä Audio g√©n√©r√©",
                    type="filepath",
                    elem_classes=["output-audio"]
                )
                clone_status = gr.Textbox(
                    label="üìã Statut",
                    interactive=False
                )
        
        # === Onglet Voice Design ===
        with gr.TabItem("‚ú® Voice Design", id="design"):
            gr.Markdown("""
            ### Cr√©er une voix personnalis√©e
            D√©crivez la voix que vous souhaitez en langage naturel.
            
            > ‚ö†Ô∏è **Note**: Cette fonctionnalit√© compl√®te n√©cessite un mod√®le Instruct. 
            > Avec le mod√®le Base, une voix par d√©faut sera utilis√©e.
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    voice_prompt_input = gr.Textbox(
                        label="üé≠ Description de la voix",
                        placeholder="Ex: Une voix f√©minine douce et chaleureuse, avec un l√©ger accent du sud...",
                        lines=4
                    )
                    
                    # Exemples de prompts
                    gr.Examples(
                        examples=[
                            ["Une voix masculine grave et pos√©e, comme un narrateur de documentaire"],
                            ["Une voix f√©minine joyeuse et dynamique, comme une animatrice radio"],
                            ["Une voix douce et apaisante, parfaite pour la m√©ditation"],
                            ["A deep male voice with a British accent, formal and elegant"],
                        ],
                        inputs=voice_prompt_input,
                        label="üí° Exemples de prompts"
                    )
                
                with gr.Column(scale=1):
                    text_design_input = gr.Textbox(
                        label="‚úçÔ∏è Texte √† synth√©tiser",
                        placeholder="Entrez le texte que vous voulez faire dire...",
                        lines=5
                    )
                    
                    design_btn = gr.Button(
                        "üöÄ G√©n√©rer l'audio",
                        variant="primary",
                        size="lg",
                        elem_classes=["generate-btn"]
                    )
            
            with gr.Row():
                design_output = gr.Audio(
                    label="üîä Audio g√©n√©r√©",
                    type="filepath",
                    elem_classes=["output-audio"]
                )
                design_status = gr.Textbox(
                    label="üìã Statut",
                    interactive=False
                )
        
        # === Onglet Ollama Chat ===
        with gr.TabItem("ü¶ô Parler avec Ollama", id="ollama"):
            gr.Markdown("""
            ### Discutez avec une IA et √©coutez ses r√©ponses
            Envoyez un message √† Ollama, la r√©ponse sera convertie en audio.
            
            > üí° **Astuce**: Assurez-vous qu'Ollama est lanc√© (`ollama serve` dans un terminal).
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    ollama_model_dropdown = gr.Dropdown(
                        choices=OLLAMA_MODELS,
                        value="qwen3:0.6b",
                        label="ü¶ô Mod√®le Ollama",
                        info="Mod√®le de langage √† utiliser",
                        allow_custom_value=True
                    )
                    
                    system_prompt_input = gr.Textbox(
                        label="üé≠ System Prompt",
                        placeholder="Ex: Tu es un assistant amical qui r√©pond en fran√ßais de mani√®re concise...",
                        value="Tu es un assistant vocal amical. R√©ponds de mani√®re concise et naturelle en fran√ßais, comme si tu parlais √† quelqu'un. Limite tes r√©ponses √† 2-3 phrases maximum.",
                        lines=3
                    )
                    
                    # Upload de voix personnalis√©e
                    ollama_ref_audio = gr.Audio(
                        label="üé§ Voix personnalis√©e (optionnel - glissez un fichier ou enregistrez)",
                        type="filepath",
                        sources=["upload", "microphone"]
                    )
                    
                    clear_chat_btn = gr.Button(
                        "üóëÔ∏è Effacer la conversation",
                        variant="secondary"
                    )
                
                with gr.Column(scale=2):
                    # Historique de chat
                    chat_history_state = gr.State([])
                    
                    chatbox = gr.Chatbot(
                        label="üí¨ Conversation",
                        height=300
                    )
                    
                    with gr.Row():
                        user_input = gr.Textbox(
                            label="‚úçÔ∏è Votre message",
                            placeholder="Tapez votre message ici...",
                            lines=2,
                            scale=4
                        )
                        send_btn = gr.Button(
                            "üì§ Envoyer",
                            variant="primary",
                            scale=1,
                            elem_classes=["generate-btn"]
                        )
            
            with gr.Row():
                ollama_audio_output = gr.Audio(
                    label="üîä R√©ponse audio",
                    type="filepath",
                    autoplay=True,  # Lecture automatique !
                    elem_classes=["output-audio"]
                )
                ollama_status = gr.Textbox(
                    label="üìã Statut",
                    interactive=False
                )
    
    # Pied de page
    gr.Markdown("""
    ---
    <div style="text-align: center; color: #6b7280; font-size: 0.9rem;">
        <p>üöÄ Propuls√© par <strong>Qwen3-TTS</strong> d'Alibaba | ü¶ô <strong>Ollama</strong> | üçé Optimis√© pour Mac Apple Silicon</p>
    </div>
    """)
    
    # === √âv√©nements ===
    
    # Voice Clone - g√©rer les deux types d'entr√©e audio
    def handle_clone(model, device, text, lang, audio_upload, audio_record, ref_text, progress=gr.Progress()):
        # Priorit√© √† l'enregistrement si disponible
        if audio_record is not None:
            return generate_voice_clone(model, device, text, lang, audio_record, ref_text, progress)
        elif audio_upload is not None:
            return generate_voice_clone(model, device, text, lang, audio_upload, ref_text, progress)
        else:
            return None, "‚ùå Veuillez importer ou enregistrer un audio de r√©f√©rence."
    
    clone_btn.click(
        fn=handle_clone,
        inputs=[
            model_dropdown, device_dropdown, text_clone_input, language_dropdown,
            ref_audio_upload, ref_audio_record, ref_text_input
        ],
        outputs=[clone_output, clone_status]
    )
    
    # Voice Design
    design_btn.click(
        fn=generate_voice_design,
        inputs=[
            model_dropdown, device_dropdown, text_design_input, 
            language_dropdown, voice_prompt_input
        ],
        outputs=[design_output, design_status]
    )
    
    # Ollama Chat
    def handle_ollama_chat(model, device, user_msg, sys_prompt, ollama_model, lang, history, ref_audio):
        audio, new_history, status = chat_with_ollama(
            model, device, user_msg, sys_prompt, ollama_model, lang, history, ref_audio
        )
        # Formater l'historique pour le chatbot Gradio 6 (format messages)
        formatted_history = []
        for msg in new_history:
            role = "user" if msg[0] == "Vous" else "assistant"
            formatted_history.append({"role": role, "content": msg[1]})
        return audio, new_history, formatted_history, status, ""
    
    send_btn.click(
        fn=handle_ollama_chat,
        inputs=[
            model_dropdown, device_dropdown, user_input, system_prompt_input,
            ollama_model_dropdown, language_dropdown, chat_history_state, ollama_ref_audio
        ],
        outputs=[ollama_audio_output, chat_history_state, chatbox, ollama_status, user_input]
    )
    
    # Aussi envoyer avec Entr√©e
    user_input.submit(
        fn=handle_ollama_chat,
        inputs=[
            model_dropdown, device_dropdown, user_input, system_prompt_input,
            ollama_model_dropdown, language_dropdown, chat_history_state, ollama_ref_audio
        ],
        outputs=[ollama_audio_output, chat_history_state, chatbox, ollama_status, user_input]
    )
    
    # Effacer la conversation
    def clear_conversation():
        return [], [], None, "üóëÔ∏è Conversation effac√©e."
    
    clear_chat_btn.click(
        fn=clear_conversation,
        outputs=[chat_history_state, chatbox, ollama_audio_output, ollama_status]
    )


# ============================================================
# Lancement
# ============================================================

if __name__ == "__main__":
    print("=" * 60)
    print("üéµ Qwen3-TTS Studio")
    print("=" * 60)
    print(f"\nüì± Devices disponibles: {get_device_info()}")
    print(f"ü§ñ Mod√®les: {list(MODELS.keys())}")
    print("\nüåê D√©marrage de l'interface web...")
    print("   L'application s'ouvrira automatiquement dans votre navigateur.\n")
    
    app.launch(
        share=False,
        inbrowser=True,
        server_name="0.0.0.0",
        server_port=7860
    )
